{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Out of stock\n",
      "delivery_estimate_to_zip_2:  Out of stock\n",
      "date_string:  Out of stock\n",
      "['Out of stock']\n",
      "date_string:  Out of stock\n",
      "['Out of stock']\n",
      "ship_zip_code_1:  ['Out of stock']\n",
      "ship_zip_code_2:  ['Out of stock']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                            | 1/13 [00:53<10:47, 53.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▊                                                                      | 2/13 [02:58<13:46, 75.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▏                                                               | 3/13 [05:28<16:15, 97.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives tomorrow\n",
      "delivery_estimate_to_zip_2:  Arrives Dec 15\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "date_string:  Dec 15\n",
      "['2']\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1]\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▏                                                        | 4/13 [07:38<16:06, 107.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives Dec 20\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  Dec 20\n",
      "['7']\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▌                                                  | 5/13 [09:59<15:39, 117.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▊                                            | 6/13 [12:10<14:09, 121.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▏                                     | 7/13 [14:30<12:42, 127.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Out of stock\n",
      "delivery_estimate_to_zip_2:  Out of stock\n",
      "date_string:  Out of stock\n",
      "['Out of stock']\n",
      "date_string:  Out of stock\n",
      "['Out of stock']\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5', 'Out of stock']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1, 'Out of stock']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▍                               | 8/13 [15:22<08:42, 104.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives Dec 20\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  Dec 20\n",
      "['7']\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5', 'Out of stock', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1, 'Out of stock', '7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████▊                         | 9/13 [17:34<07:31, 112.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives Dec 20\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  Dec 20\n",
      "['7']\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5', 'Out of stock', '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1, 'Out of stock', '7', '7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████▎                  | 10/13 [19:41<05:51, 117.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5', 'Out of stock', '5', '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1, 'Out of stock', '7', '7', 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████▌            | 11/13 [21:51<04:01, 120.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5', 'Out of stock', '5', '5', '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1, 'Out of stock', '7', '7', 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████▊      | 12/13 [24:08<02:05, 125.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_estimate_to_zip_1:  Arrives Dec 18\n",
      "delivery_estimate_to_zip_2:  Arrives tomorrow\n",
      "date_string:  Dec 18\n",
      "['5']\n",
      "date_string:  tomorrow\n",
      "date_string:  tomorrow\n",
      "ship_zip_code_1:  ['Out of stock', '5', '5', 1, '5', '5', '5', 'Out of stock', '5', '5', '5', '5', '5']\n",
      "ship_zip_code_2:  ['Out of stock', 1, 1, '2', '7', 1, 1, 'Out of stock', '7', '7', 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [26:18<00:00, 121.44s/it]\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# 1. # IMPORTING LIBRARIES #\n",
    "############################\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import pytz\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from seleniumbase import Driver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "log_folder = 'logs'\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "\n",
    "log_filename = os.path.join(log_folder, f\"log_file_{timestamp}.log\")\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    filename=log_filename,\n",
    "                    filemode='w')\n",
    "\n",
    "\n",
    "\n",
    "def create_directory():\n",
    "    list_of_dir = [\"./Data\", \"./Output\", \"./Exceptions\", \"./Lookup\"]\n",
    "    for dir_name in list_of_dir:\n",
    "        try:\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "            logging.info(f\"Directory '{dir_name}' created successfully\")\n",
    "        except OSError as error:\n",
    "            logging.error(f\"Creation of the directory '{dir_name}' failed due to: {error}\")\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "# 2. # URL EXTRACTOR FUNCTION #\n",
    "###############################\n",
    "def get_urls():\n",
    "    \n",
    "    ###############################################################\n",
    "    # 2. # EXTRACTING NUMBER OF PAGES FROM SIMPLEHUMAN BRAND PAGE #\n",
    "    ###############################################################\n",
    "\n",
    "    # Set a custom user-agent to mimic a real user\n",
    "    driver = Driver(uc=True)\n",
    "    url = 'https://www.walmart.com/search?q=simplehuman&facet=brand%3Asimplehuman&affinityOverride=default'\n",
    "\n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Find all the page number elements using the 'data-automation-id' attribute\n",
    "    page_number_elements = driver.find_elements(By.CSS_SELECTOR, 'a[data-automation-id=\"page-number\"]')\n",
    "\n",
    "    # Initialize an empty list to store the page numbers\n",
    "    page_numbers = []\n",
    "\n",
    "    # Iterate through the page number elements and extract the text\n",
    "    for element in page_number_elements:\n",
    "        page_numbers.append(element.text)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    # Print the extracted page numbers\n",
    "    print('List of Page Numbers:',page_numbers)\n",
    "\n",
    "    ##########################################################\n",
    "    # 3. # SCRAPPING PRODUCT NAME AND LINKS FROM BRAND PAGES #\n",
    "    ##########################################################\n",
    "\n",
    "    # Initialize lists to store item names and links\n",
    "    item_names = []\n",
    "    item_links = []\n",
    "\n",
    "    for page in tqdm(page_numbers):\n",
    "        # Create a new WebDriver session for each URL\n",
    "        #driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "        driver = Driver(uc=True)\n",
    "        #driver.get(website)\n",
    "        url = f'https://www.walmart.com/search?q=_&facet=brand%3Asimplehuman&page={page}'\n",
    "\n",
    "        # Navigate to the URL\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load (you may need to adjust the waiting time)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        human_dialog = driver.find_elements(By.XPATH, \"//div[@aria-labelledby='ld_modalTitle_0']\")\n",
    "        while human_dialog:\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            human_dialog = driver.find_elements(By.XPATH, \"//div[@aria-labelledby='ld_modalTitle_0']\")\n",
    "            logging.warning('ROBOT or HUMAN Verfication FOUND!')\n",
    "\n",
    "        # Get the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Find all div elements with the specified class\n",
    "        item_divs = soup.find_all('div', class_='mb0 ph1 pa0-xl bb b--near-white w-25')\n",
    "\n",
    "        # Iterate through the found div elements\n",
    "        for item_div in item_divs:\n",
    "            # Find the nested div that contains the item information\n",
    "            nested_div = item_div.find('div', class_='h-100 pb1-xl pr4-xl pv1 ph1')\n",
    "\n",
    "            if nested_div:\n",
    "                # Extract the link and item name from the nested div\n",
    "                link = nested_div.find('a', href=True)['href']\n",
    "                name = nested_div.find('span', class_='w_iUH7').text.strip()\n",
    "\n",
    "                # Append to the respective lists\n",
    "                item_names.append(name)\n",
    "                item_links.append(link)\n",
    "\n",
    "        logging.info(f'Data Extracted for Page: {page}')\n",
    "\n",
    "        # Close the Selenium WebDriver\n",
    "        driver.quit()\n",
    "    \n",
    "    print('Length of the Lists should be 150+:',len(item_links),len(item_names))\n",
    "\n",
    "    ##############################################\n",
    "    # 4. # CONVERRTING LINKS INTO CORRECT FORMAT #\n",
    "    ##############################################\n",
    "\n",
    "    # Function to convert Type-1 link\n",
    "    def convert_type1_link(link):\n",
    "        return \"https://www.walmart.com\" + re.sub(r'\\?.*$', '', link)\n",
    "\n",
    "    # Function to convert Type-2 link and extract up to the first unique code\n",
    "    def convert_type2_link(link):\n",
    "        match = re.search(r'rd=(https%3A%2F%2Fwww\\.walmart\\.com.*?%2F(\\d+))', link)\n",
    "        if match:\n",
    "            return match.group(1).replace('%2F', '/').replace('%3A',':')\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Convert all links in the list\n",
    "    converted_links = []\n",
    "\n",
    "    for link in item_links:\n",
    "        if link.startswith(\"/\"):\n",
    "            converted_link = convert_type1_link(link)\n",
    "        else:\n",
    "            converted_link = convert_type2_link(link)\n",
    "\n",
    "        if converted_link:\n",
    "            converted_links.append(converted_link)\n",
    "\n",
    "    #############################\n",
    "    # 5. # EXPORTING THE OUTPUT #\n",
    "    #############################\n",
    "\n",
    "    df_= pd.DataFrame()\n",
    "    df_['Name']=item_names\n",
    "    df_['Link']=converted_links\n",
    "    df_.to_excel('Data/Walmart_Links.xlsx',index=False)\n",
    "    logging.info('Formatted Links File Exported.')\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# 3. # WEB SCRAPPING #\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "def set_zip_code_and_get_message(driver, zip_code):\n",
    "    date_text = \"\"\n",
    "    try:\n",
    "        try:\n",
    "            driver.refresh()\n",
    "            element = driver.find_element(By.XPATH,\"//div[contains(text(),'Out of stock')]\")\n",
    "            date_text = element.text\n",
    "            #print(date_text)\n",
    "        except:\n",
    "            try:\n",
    "                # Find and click the button with the specified class\n",
    "                zip_click_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@aria-label, 'Delivery to') and contains(@class, 'pointer')]\")))\n",
    "                zip_click_button.click()\n",
    "\n",
    "            except TimeoutException:\n",
    "                # If an exception occurs, click the \"Change\" button\n",
    "                change_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Change shipping address']\")))\n",
    "                change_button.click()\n",
    "\n",
    "            time.sleep(10)\n",
    "\n",
    "            input_element = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"input[autocomplete='postal-code']\")))\n",
    "            input_element.send_keys(Keys.END)  # Go to the end of the input field\n",
    "            input_element.send_keys(Keys.HOME + Keys.SHIFT + Keys.END)  # Select the entire text\n",
    "            input_element.send_keys(Keys.BACK_SPACE)  # Clear the selected text\n",
    "            input_element.send_keys(zip_code)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            save_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[form='update-postal-code-form']\")))\n",
    "            save_button.click()\n",
    "\n",
    "            time.sleep(15) # allow page to refresh\n",
    "\n",
    "            # Extract the text  \n",
    "            date_text = driver.find_element(By.CSS_SELECTOR, 'div.f7.mt1.ws-normal.ttn').text\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        date_text = 'Out of Stock'\n",
    "    return date_text\n",
    "    \n",
    "    \n",
    "def calculate_days_remaining(date_string):\n",
    "    # Define the current date in PST (Pacific Standard Time)\n",
    "    pst = pytz.timezone('US/Pacific')\n",
    "    date_string = date_string.strip(\"Arrives \")\n",
    "    current_date_pst = datetime.now(pst).date()\n",
    "\n",
    "\n",
    "    # Initialize an empty list to store the number of days\n",
    "    days_difference = []\n",
    "    \n",
    "    print(\"date_string: \",date_string)\n",
    "\n",
    "    # Remove the \"(Est.)\" and any surrounding whitespace using strip\n",
    "    #date_string = date_string.strip()\n",
    "    try:\n",
    "        try:\n",
    "            if date_string.lower() == 'today':\n",
    "                return 0\n",
    "        \n",
    "            elif date_string.lower() == 'tomorrow':\n",
    "                return 1\n",
    "        \n",
    "            # Check if the string contains a date\n",
    "            delivery_date = parser.parse(date_string).date()\n",
    "            # Calculate the time difference in days (delivery date - current date)\n",
    "            time_difference = (delivery_date - current_date_pst).days\n",
    "\n",
    "            # Append the number of days to the list\n",
    "            days_difference.append(str(time_difference))\n",
    "        except:\n",
    "            # Handle the case where delivery is unavailable\n",
    "            days_difference.append(date_string)\n",
    "    except:\n",
    "        days_difference.append('-')\n",
    "        \n",
    "    print(days_difference)\n",
    "             \n",
    "    return days_difference\n",
    "\n",
    "def stock_information_extractor(zip_code):\n",
    "    if 'out of stock' in zip_code.lower():\n",
    "        return 'Out of Stock'\n",
    "    elif 'discontinued' in zip_code.lower().lower():\n",
    "        return 'Discontinued'\n",
    "    elif 'unavailable' in zip_code.lower().lower():\n",
    "        return 'Not Available'\n",
    "    else:\n",
    "        return 'Available'\n",
    "\n",
    "def scrapper(df_link):\n",
    "    \n",
    "    ############ Variables ###################    \n",
    "    product_name_list = []\n",
    "    product_price_list = []\n",
    "    zip_1_stock = []\n",
    "    zip_2_stock = []\n",
    "    ship_zip_code_1 = []\n",
    "    ship_zip_code_2 = []\n",
    "    product_url_list = []\n",
    "    \n",
    "    product_price = \"\"\n",
    "    product_name = \"\"\n",
    "    delivery_estimate_to_zip_1 = \"\"\n",
    "    delivery_estimate_to_zip_1 = \"\"\n",
    "    error = []\n",
    "\n",
    "    link_list = df_link['Link'].to_list() #list of extracted link for different items \n",
    "    link_list = link_list[12:25]\n",
    "    \n",
    "    for link in tqdm(link_list):\n",
    "        driver = Driver(uc=True)\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        \n",
    "       \n",
    "        #print(link)\n",
    "        # TITLE:\n",
    "        product_name = driver.find_element(By.ID,\"main-title\").text\n",
    "        #print(product_name)\n",
    "\n",
    "        product_price = driver.find_element(By.CSS_SELECTOR,'span[data-testid=\"price-wrap\"] span[itemprop=\"price\"]').text\n",
    "        #print(product_price)\n",
    "        if 'Now' in product_price:\n",
    "            product_price = product_price.strip('Now')\n",
    "\n",
    "        delivery_estimate_to_zip_1 = set_zip_code_and_get_message(driver,'90501')\n",
    "        print(\"delivery_estimate_to_zip_1: \",delivery_estimate_to_zip_1)\n",
    "        #print('Zip-1:',zip_1)\n",
    "        time.sleep(15)\n",
    "\n",
    "        delivery_estimate_to_zip_2 = set_zip_code_and_get_message(driver,'08404')\n",
    "        print(\"delivery_estimate_to_zip_2: \",delivery_estimate_to_zip_2)\n",
    "        #print('Zip-2:',zip_2)\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        product_name_list.append(product_name)\n",
    "        product_price_list.append(product_price)\n",
    "\n",
    "        try:\n",
    "            ship_zip_code_1.append(calculate_days_remaining(delivery_estimate_to_zip_1)[0])\n",
    "        except:\n",
    "            ship_zip_code_1.append(calculate_days_remaining(delivery_estimate_to_zip_1))\n",
    "\n",
    "        try:\n",
    "            ship_zip_code_2.append(calculate_days_remaining(delivery_estimate_to_zip_2)[0])\n",
    "        except:\n",
    "            ship_zip_code_2.append(calculate_days_remaining(delivery_estimate_to_zip_2))\n",
    "\n",
    "        print(\"ship_zip_code_1: \",ship_zip_code_1)\n",
    "        print(\"ship_zip_code_2: \",ship_zip_code_2)\n",
    "\n",
    "        zip_1_stock.append(stock_information_extractor(delivery_estimate_to_zip_1))\n",
    "        zip_2_stock.append(stock_information_extractor(delivery_estimate_to_zip_2)) \n",
    "\n",
    "        product_url_list.append(link)\n",
    "    \n",
    "    ###########################\n",
    "    # 4. # EXPORTING THE FILE #\n",
    "    ###########################\n",
    "    df_prod = pd.DataFrame()\n",
    "    df_prod['Product Name'] = product_name_list\n",
    "    df_prod['Price'] = product_price_list\n",
    "    df_prod['# of days to LBC'] = ship_zip_code_1\n",
    "    df_prod['Stock for LBC'] = zip_1_stock\n",
    "    df_prod['# of days to NJ'] = ship_zip_code_2\n",
    "    df_prod['Stock for NJ'] = zip_2_stock\n",
    "    df_prod['Stock Status'] = df_prod.apply(lambda row: 'Available' if (row['Stock for LBC'] == 'Available' and row['Stock for NJ'] == 'Available') else 'Not Available', axis=1)\n",
    "    df_prod['URL'] = product_url_list\n",
    "        \n",
    "    df_prod['# of days to LBC'] = df_prod['# of days to LBC'].astype(str)\n",
    "    df_prod['# of days to NJ'] = df_prod['# of days to NJ'].astype(str)\n",
    "    \n",
    "    df_errors = pd.DataFrame(error)\n",
    "    \n",
    "    pst_time_now = datetime.now(pytz.timezone('US/Pacific')).strftime('%Y-%m-%d %H-%M-%S')\n",
    "    pst_time_now = datetime.now(pytz.timezone('US/Pacific')).strftime('%Y-%m-%d %H-%M-%S')\n",
    "    with pd.ExcelWriter(f'Output/Walmart_{pst_time_now}.xlsx') as writer:\n",
    "        df_prod.to_excel(writer, sheet_name='Main Data', index=False)\n",
    "        df_errors.to_excel(writer, sheet_name='Manual review needed', index=False)\n",
    "        \n",
    "    logging.info('Scraping completed.')\n",
    "    return df_prod\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    #urls_df = get_urls()\n",
    "    urls_df = pd.read_excel(\"Walmart_Links.xlsx\")\n",
    "    df = scrapper(urls_df)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplehuman Code H Custom Fit Drawstring Trash...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-Code-H-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simplehuman 45 Liter Rectangular Hands-Free Ki...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-45-Lite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simplehuman Code J Custom Fit Drawstring Trash...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-Code-J-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simplehuman 10 gal Stainless Steel Rectangular...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-10-gal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simplehuman 58 Liter / 15.3 gal Stainless Stee...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-58-Lite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Simplehuman Code G Custom Fit Liners, 20 Count</td>\n",
       "      <td>https://www.walmart.com/ip/Simplehuman-Code-G-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>simplehuman 12 gal Plastic Rectangular Kitchen...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-12-gal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>simplehuman Code K Custom Fit Drawstring Trash...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-Code-K-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>simplehuman Code Q Custom Fit Drawstring Trash...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-Code-Q-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>simplehuman 45 Liter / 12 gal Stainless Steel ...</td>\n",
       "      <td>https://www.walmart.com/ip/simplehuman-45-Lite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "0    simplehuman Code H Custom Fit Drawstring Trash...   \n",
       "1    simplehuman 45 Liter Rectangular Hands-Free Ki...   \n",
       "2    simplehuman Code J Custom Fit Drawstring Trash...   \n",
       "3    simplehuman 10 gal Stainless Steel Rectangular...   \n",
       "4    simplehuman 58 Liter / 15.3 gal Stainless Stee...   \n",
       "..                                                 ...   \n",
       "166     Simplehuman Code G Custom Fit Liners, 20 Count   \n",
       "167  simplehuman 12 gal Plastic Rectangular Kitchen...   \n",
       "168  simplehuman Code K Custom Fit Drawstring Trash...   \n",
       "169  simplehuman Code Q Custom Fit Drawstring Trash...   \n",
       "170  simplehuman 45 Liter / 12 gal Stainless Steel ...   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://www.walmart.com/ip/simplehuman-Code-H-...  \n",
       "1    https://www.walmart.com/ip/simplehuman-45-Lite...  \n",
       "2    https://www.walmart.com/ip/simplehuman-Code-J-...  \n",
       "3    https://www.walmart.com/ip/simplehuman-10-gal-...  \n",
       "4    https://www.walmart.com/ip/simplehuman-58-Lite...  \n",
       "..                                                 ...  \n",
       "166  https://www.walmart.com/ip/Simplehuman-Code-G-...  \n",
       "167  https://www.walmart.com/ip/simplehuman-12-gal-...  \n",
       "168  https://www.walmart.com/ip/simplehuman-Code-K-...  \n",
       "169  https://www.walmart.com/ip/simplehuman-Code-Q-...  \n",
       "170  https://www.walmart.com/ip/simplehuman-45-Lite...  \n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
